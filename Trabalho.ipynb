{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregamento das bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-10T00:44:12.514627Z",
     "start_time": "2021-06-10T00:44:12.509125Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchtext import datasets\n",
    "from string import punctuation\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregamengo do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-10T00:50:27.424355Z",
     "start_time": "2021-06-10T00:49:16.448387Z"
    }
   },
   "outputs": [],
   "source": [
    "train_iter, test_iter = datasets.IMDB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conversão para tipagem do Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(train_iter, columns=['target','value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neg</td>\n",
       "      <td>I love sci-fi and am willing to put up with a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neg</td>\n",
       "      <td>Worth the entertainment value of a rental, esp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neg</td>\n",
       "      <td>its a totally average film with a few semi-alr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neg</td>\n",
       "      <td>STAR RATING: ***** Saturday Night **** Friday ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neg</td>\n",
       "      <td>First off let me say, If you haven't enjoyed a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target                                              value\n",
       "0    neg  I love sci-fi and am willing to put up with a ...\n",
       "1    neg  Worth the entertainment value of a rental, esp...\n",
       "2    neg  its a totally average film with a few semi-alr...\n",
       "3    neg  STAR RATING: ***** Saturday Night **** Friday ...\n",
       "4    neg  First off let me say, If you haven't enjoyed a..."
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.DataFrame(test_iter, columns=['target','value'])\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une ambos os dataset's em um único"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neg</td>\n",
       "      <td>I rented I AM CURIOUS-YELLOW from my video sto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neg</td>\n",
       "      <td>\"I Am Curious: Yellow\" is a risible and preten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neg</td>\n",
       "      <td>If only to avoid making this type of film in t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neg</td>\n",
       "      <td>This film was probably inspired by Godard's Ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neg</td>\n",
       "      <td>Oh, brother...after hearing about this ridicul...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target                                              value\n",
       "0    neg  I rented I AM CURIOUS-YELLOW from my video sto...\n",
       "1    neg  \"I Am Curious: Yellow\" is a risible and preten...\n",
       "2    neg  If only to avoid making this type of film in t...\n",
       "3    neg  This film was probably inspired by Godard's Ma...\n",
       "4    neg  Oh, brother...after hearing about this ridicul..."
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data = df_train.append(df_test)\n",
    "\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Código para obter apenas uma quantidade de exemplares de cada classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_data = df_data.groupby('target').apply(lambda s: s.sample(10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotagem de distribuição dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neg    25000\n",
       "pos    25000\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_data.target.value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplica um pré-processamento nos dados, tais como:\n",
    "\n",
    "* Remoção de pontuação\n",
    "* definição do texto todo para minúsculo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neg</td>\n",
       "      <td>i rented i am curiousyellow from my video stor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neg</td>\n",
       "      <td>i am curious yellow is a risible and pretentio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neg</td>\n",
       "      <td>if only to avoid making this type of film in t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neg</td>\n",
       "      <td>this film was probably inspired by godards mas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neg</td>\n",
       "      <td>oh brotherafter hearing about this ridiculous ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target                                              value\n",
       "0    neg  i rented i am curiousyellow from my video stor...\n",
       "1    neg  i am curious yellow is a risible and pretentio...\n",
       "2    neg  if only to avoid making this type of film in t...\n",
       "3    neg  this film was probably inspired by godards mas...\n",
       "4    neg  oh brotherafter hearing about this ridiculous ..."
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_data(x):\n",
    "    all_text = ''.join(c for c in x if c not in punctuation)\n",
    "    return all_text.lower()\n",
    "\n",
    "df_data = df_data.assign(value = df_data.value.apply(lambda x: preprocess_data(x)))\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cria uma tokenização com todas as palavras. A ideia é verificar as palavras mais comuns e como estão distribuídas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Junta todos os textos\n",
    "all_text = ' '.join(df_data.value.values)\n",
    "\n",
    "# Separa por palavras\n",
    "words = all_text.split()\n",
    "\n",
    "# Faz a contagem por palavras\n",
    "count_words = Counter(words)\n",
    "\n",
    "# Total de palavras\n",
    "total_words = len(words)\n",
    "\n",
    "# Faz a ordenação de palavras\n",
    "sorted_words = count_words.most_common(total_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faz uma conversão das palavras para serem representadas por um valor numérico inteiro, iniciando em 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_to_int = {w:i+1 for i, (w,c) in enumerate(sorted_words)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplica a transformação de valores para inteiro nos reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 1501, 9, 226, 51851, 35, 53, 386, 1095, 83, 4, 31, 1, 6453, 11, 3541, 8, 50, 8, 13, 87, 607, 7, 7836, 9, 80, 537, 11, 30, 87, 8, 13, 23503, 32, 169, 9265, 43, 8, 120, 742, 5, 2254, 10, 686, 1498, 106, 3, 320, 4, 95, 1174, 2865, 9, 62, 67, 5, 64, 10, 16, 15708, 12, 1, 114, 6, 5762, 181, 3, 182, 3616, 476, 1425, 756, 5997, 36, 478, 5, 828, 263, 58, 68, 42, 119, 7, 835, 58, 478, 5, 1127, 41, 15073, 5, 251, 46, 418, 4, 657, 20, 48, 1, 859, 26431, 194, 42, 734, 987, 1230, 136, 14, 1, 2444, 310, 2, 1392, 1230, 7, 1, 2195, 1585, 7, 197, 2110, 5998, 2, 1806, 21911, 4, 19962, 42, 63, 3990, 20, 2517, 58, 44, 381, 15, 41, 476, 1643, 9482, 2, 1045, 11683, 12, 48, 1116, 69, 42, 9, 226, 51851, 6, 11, 1973, 151, 605, 10, 13, 1174, 8101, 62, 1, 381, 2, 1051, 134, 23, 167, 2, 224, 197, 54, 90, 29, 21, 315, 38, 46, 6935, 92, 3904, 133, 53, 27652, 337, 159, 8, 1540, 7, 615, 381, 2, 1051, 23, 3, 630, 8548, 7, 3616, 450, 54, 11861, 3748, 4677, 63, 1439, 5, 49, 168, 438, 308, 1838, 67, 381, 134, 7, 24, 3482, 12, 9, 78, 13234, 1, 894, 16, 1, 187, 11, 97, 381, 580, 7, 1, 19, 6, 580, 16, 1581, 4886, 241, 70, 40, 5, 1490, 84, 2, 94, 291, 5, 26, 580, 7, 8101, 2148, 7, 944, 9, 226, 51851, 6, 3, 49, 19, 16, 245, 1623, 5, 1981, 1, 3341, 2, 18404, 55, 4974, 1345, 4, 3616, 450, 18, 62, 10, 19, 148, 25, 72, 4, 3, 114]\n"
     ]
    }
   ],
   "source": [
    "reviews_int = []\n",
    "\n",
    "for review in df_data.value.values:\n",
    "    r = [vocab_to_int[w] for w in review.split()]\n",
    "    reviews_int.append(r)\n",
    "\n",
    "print(reviews_int[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faz o encoding dos label's para inteiro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_labels = [1 if label == 'pos' else 0 for label in df_data.target.values]\n",
    "encoded_labels = np.array(encoded_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faz um plot dos dados para verificar como estão as distribuições. É possível ver que o gráfico não está normalizado, o que significa que possuem outliers.\n",
    "\n",
    "Outro detalhe importante é que dá para ver que tem alguns reviews que são muito longos.\n",
    "\n",
    "Partindo disto, a ideia é removermos esses reviews com muito ou pouco review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "count    50000.000000\n",
       "mean       230.258240\n",
       "std        170.663887\n",
       "min          4.000000\n",
       "25%        126.000000\n",
       "50%        172.000000\n",
       "75%        280.000000\n",
       "max       2469.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_len = [len(x) for x in reviews_int]\n",
    "pd.Series(reviews_len).hist()\n",
    "plt.show()\n",
    "\n",
    "pd.Series(reviews_len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove todo review que não tiver, ao menos 1 palavra\n",
    "reviews_int = [reviews_int[i] for i, l in enumerate(reviews_len) if l > 0]\n",
    "encoded_labels = [encoded_labels[i] for i, l in enumerate(reviews_len) if l > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Efetua o processo de padding/truncate dos dados. A ideia é que todos os reviews fiquem com o mesmo tamanho, afinal, o objeto da rede neural é que a entrada seja um número fixo de neurônios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O valor padrão do seq_length é baseado no 3º quartil\n",
    "def pad_features(reviews_int, seq_length=280):\n",
    "    # Cria uma matriz zerada - a ideia é que, os espaços vazios sejam preenchidos com 0\n",
    "    features = np.zeros((len(reviews_int), seq_length), dtype=int)\n",
    "\n",
    "    for i, review in enumerate(reviews_int):\n",
    "        reviews_len = len(review)\n",
    "\n",
    "        if reviews_len <= seq_length:\n",
    "            zeroes = list(np.zeros(seq_length - reviews_len))\n",
    "            new = zeroes + review\n",
    "        elif reviews_len > seq_length:\n",
    "            new = review[0:seq_length]\n",
    "        \n",
    "        features[i, :] = np.array(new)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui, a lista de features ficará com 280 de tamanho, para cada review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pad_features(reviews_int)\n",
    "len_feats = len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 280)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features), len(features[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separa em Train, Valid, Test\n",
    "\n",
    "* 80% para treino\n",
    "* 10% para valid\n",
    "* 10% para test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT_FRAC = 0.8\n",
    "\n",
    "FACTOR = int(SPLIT_FRAC * len_feats)\n",
    "\n",
    "train_x = np.array(features[0:FACTOR])\n",
    "train_y = np.array(encoded_labels[0:FACTOR])\n",
    "\n",
    "remain_x = np.array(features[FACTOR:])\n",
    "remain_y = np.array(encoded_labels[FACTOR:])\n",
    "\n",
    "REMAIN_FACTOR = int(len(remain_x) * 0.5)\n",
    "\n",
    "valid_x = np.array(remain_x[0:REMAIN_FACTOR])\n",
    "valid_y = np.array(remain_y[0:REMAIN_FACTOR])\n",
    "\n",
    "test_x = np.array(remain_x[REMAIN_FACTOR:])\n",
    "test_y = np.array(remain_y[0:REMAIN_FACTOR:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualiza o tamanho dos dataset's de treino, validação e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000 280\n",
      "5000 280\n",
      "5000 280\n"
     ]
    }
   ],
   "source": [
    "print(len(train_x), len(train_x[0]))\n",
    "print(len(valid_x), len(valid_x[0]))\n",
    "print(len(test_x), len(test_x[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataloaders e batching\n",
    "\n",
    "A ideia de fazer o drop_last é com intuito de ter todos os batches com o mesmo tamanho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
    "valid_data = TensorDataset(torch.from_numpy(valid_x), torch.from_numpy(valid_y))\n",
    "test_data  = TensorDataset(torch.from_numpy(test_x),  torch.from_numpy(test_y))\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=BATCH_SIZE, drop_last=True)\n",
    "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=BATCH_SIZE, drop_last=True)\n",
    "test_loader  = DataLoader(test_data,  shuffle=True, batch_size=BATCH_SIZE, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample input size:  torch.Size([64, 280])\n",
      "Sample input:  tensor([[    0,     0,     0,  ...,   181,    45,    47],\n",
      "        [    0,     0,     0,  ...,   535, 26148,   155],\n",
      "        [    0,     0,     0,  ...,     4,    10,    17],\n",
      "        ...,\n",
      "        [    0,     0,     0,  ...,    26,   546,   760],\n",
      "        [ 2608,  8243,     1,  ..., 11014,    36,   658],\n",
      "        [    0,     0,     0,  ...,    45,     4,   723]])\n",
      "Sample label size:  torch.Size([64])\n",
      "Sample label:  tensor([1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1,\n",
      "        0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
      "        1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "# Exibição de um exemplo de dados\n",
    "\n",
    "data_iter = iter(train_loader)\n",
    "sample_x, sample_y = data_iter.next()\n",
    "\n",
    "print('Sample input size: ', sample_x.size())\n",
    "print('Sample input: ', sample_x)\n",
    "print('Sample label size: ', sample_y.size())\n",
    "print('Sample label: ', sample_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define o modelo da classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n",
    "        # Efetua a inicializacao do modelo\n",
    "        super().__init__()\n",
    "\n",
    "        # Define a quantidade de neuronios de saida, numero de layers e tamanho da camada escondida\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # Cria o Embedding e a LSTM\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=drop_prob, batch_first=True)\n",
    "\n",
    "        # Define um dropout de 0.3, para apagar uma parte dos pesos\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        self.sig = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "        # Define o funcionamento do modelo\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        embeds = self.embedding(x)\n",
    "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
    "\n",
    "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
    "\n",
    "        out = self.dropout(lstm_out)\n",
    "        out = self.fc(out)\n",
    "\n",
    "        sig_out = self.sig(out)\n",
    "\n",
    "        sig_out = sig_out.view(batch_size, -1)\n",
    "        sig_out = sig_out[:, -1]\n",
    "\n",
    "        return sig_out, hidden\n",
    "    \n",
    "    # Define e inicializa as camadas ocultas\n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "\n",
    "        hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(), \n",
    "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
    "        \n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treinamento da rede, inicia com a definição dos parâmetros, como tamanho total do vocabulário, quantidade de neurônios nas camadas escondidas e de saída, número de camadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentimentLSTM(\n",
       "  (embedding): Embedding(181686, 400)\n",
       "  (lstm): LSTM(400, 128, num_layers=4, batch_first=True, dropout=0.5)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (sig): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB_SIZE = len(vocab_to_int) + 1 # porque o indice inicia em 0 e deve ser iniciado em 1\n",
    "OUTPUT_SIZE = 1\n",
    "EMBEDDING_DIM = 400\n",
    "HIDDEN_DIM = 128\n",
    "N_LAYERS = 4\n",
    "\n",
    "model = SentimentLSTM(VOCAB_SIZE, OUTPUT_SIZE, EMBEDDING_DIM, HIDDEN_DIM, N_LAYERS)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "Epoch: 1/10... Step: 100... Loss: 0.609037... Val Loss: 0.974583\n",
      "Epoch: 1/10... Step: 200... Loss: 0.676484... Val Loss: 1.041060\n",
      "Epoch: 1/10... Step: 300... Loss: 0.453250... Val Loss: 0.675144\n",
      "Epoch: 1/10... Step: 400... Loss: 0.468367... Val Loss: 1.011498\n",
      "Epoch: 1/10... Step: 500... Loss: 0.544220... Val Loss: 0.325990\n",
      "Epoch: 1/10... Step: 600... Loss: 0.359136... Val Loss: 0.395054\n",
      "epoch: 1\n",
      "Epoch: 2/10... Step: 700... Loss: 0.267234... Val Loss: 0.904478\n",
      "Epoch: 2/10... Step: 800... Loss: 0.230600... Val Loss: 0.615921\n",
      "Epoch: 2/10... Step: 900... Loss: 0.317629... Val Loss: 0.400452\n",
      "Epoch: 2/10... Step: 1000... Loss: 0.490504... Val Loss: 0.546991\n",
      "Epoch: 2/10... Step: 1100... Loss: 0.274251... Val Loss: 0.546520\n",
      "Epoch: 2/10... Step: 1200... Loss: 0.315838... Val Loss: 0.712836\n",
      "epoch: 2\n",
      "Epoch: 3/10... Step: 1300... Loss: 0.180360... Val Loss: 0.370921\n",
      "Epoch: 3/10... Step: 1400... Loss: 0.184212... Val Loss: 0.757051\n",
      "Epoch: 3/10... Step: 1500... Loss: 0.151596... Val Loss: 0.446691\n",
      "Epoch: 3/10... Step: 1600... Loss: 0.298365... Val Loss: 0.630986\n",
      "Epoch: 3/10... Step: 1700... Loss: 0.127430... Val Loss: 0.478680\n",
      "Epoch: 3/10... Step: 1800... Loss: 0.236192... Val Loss: 0.319271\n",
      "epoch: 3\n",
      "Epoch: 4/10... Step: 1900... Loss: 0.203705... Val Loss: 0.736785\n",
      "Epoch: 4/10... Step: 2000... Loss: 0.107825... Val Loss: 0.711814\n",
      "Epoch: 4/10... Step: 2100... Loss: 0.106759... Val Loss: 0.725746\n",
      "Epoch: 4/10... Step: 2200... Loss: 0.285965... Val Loss: 0.356485\n",
      "Epoch: 4/10... Step: 2300... Loss: 0.040922... Val Loss: 0.537807\n",
      "Epoch: 4/10... Step: 2400... Loss: 0.170321... Val Loss: 0.569405\n",
      "Epoch: 4/10... Step: 2500... Loss: 0.195152... Val Loss: 0.417586\n",
      "epoch: 4\n",
      "Epoch: 5/10... Step: 2600... Loss: 0.109349... Val Loss: 0.829019\n",
      "Epoch: 5/10... Step: 2700... Loss: 0.117525... Val Loss: 0.297780\n",
      "Epoch: 5/10... Step: 2800... Loss: 0.049650... Val Loss: 0.656441\n",
      "Epoch: 5/10... Step: 2900... Loss: 0.093844... Val Loss: 0.608814\n",
      "Epoch: 5/10... Step: 3000... Loss: 0.017292... Val Loss: 0.642177\n",
      "Epoch: 5/10... Step: 3100... Loss: 0.179468... Val Loss: 0.516521\n",
      "epoch: 5\n",
      "Epoch: 6/10... Step: 3200... Loss: 0.052757... Val Loss: 0.598097\n",
      "Epoch: 6/10... Step: 3300... Loss: 0.129465... Val Loss: 0.627699\n",
      "Epoch: 6/10... Step: 3400... Loss: 0.062578... Val Loss: 0.592989\n",
      "Epoch: 6/10... Step: 3500... Loss: 0.095860... Val Loss: 1.016699\n",
      "Epoch: 6/10... Step: 3600... Loss: 0.035309... Val Loss: 0.660265\n",
      "Epoch: 6/10... Step: 3700... Loss: 0.095534... Val Loss: 0.597173\n",
      "epoch: 6\n",
      "Epoch: 7/10... Step: 3800... Loss: 0.004426... Val Loss: 1.172160\n",
      "Epoch: 7/10... Step: 3900... Loss: 0.045908... Val Loss: 0.977388\n",
      "Epoch: 7/10... Step: 4000... Loss: 0.023310... Val Loss: 0.876793\n",
      "Epoch: 7/10... Step: 4100... Loss: 0.078427... Val Loss: 1.277160\n",
      "Epoch: 7/10... Step: 4200... Loss: 0.071607... Val Loss: 1.390022\n",
      "Epoch: 7/10... Step: 4300... Loss: 0.004377... Val Loss: 0.730836\n",
      "epoch: 7\n",
      "Epoch: 8/10... Step: 4400... Loss: 0.029302... Val Loss: 1.017630\n",
      "Epoch: 8/10... Step: 4500... Loss: 0.103243... Val Loss: 1.027270\n",
      "Epoch: 8/10... Step: 4600... Loss: 0.073158... Val Loss: 0.469521\n",
      "Epoch: 8/10... Step: 4700... Loss: 0.018571... Val Loss: 0.672038\n",
      "Epoch: 8/10... Step: 4800... Loss: 0.040696... Val Loss: 0.678437\n",
      "Epoch: 8/10... Step: 4900... Loss: 0.009609... Val Loss: 1.247547\n",
      "Epoch: 8/10... Step: 5000... Loss: 0.006403... Val Loss: 1.169106\n",
      "epoch: 8\n",
      "Epoch: 9/10... Step: 5100... Loss: 0.054283... Val Loss: 1.059152\n",
      "Epoch: 9/10... Step: 5200... Loss: 0.005911... Val Loss: 1.051125\n",
      "Epoch: 9/10... Step: 5300... Loss: 0.003518... Val Loss: 0.845591\n",
      "Epoch: 9/10... Step: 5400... Loss: 0.001816... Val Loss: 1.067942\n",
      "Epoch: 9/10... Step: 5500... Loss: 0.009507... Val Loss: 1.066026\n",
      "Epoch: 9/10... Step: 5600... Loss: 0.010526... Val Loss: 0.919311\n",
      "epoch: 9\n",
      "Epoch: 10/10... Step: 5700... Loss: 0.007837... Val Loss: 1.152823\n",
      "Epoch: 10/10... Step: 5800... Loss: 0.082836... Val Loss: 1.275656\n",
      "Epoch: 10/10... Step: 5900... Loss: 0.023429... Val Loss: 1.306675\n",
      "Epoch: 10/10... Step: 6000... Loss: 0.004288... Val Loss: 1.012741\n",
      "Epoch: 10/10... Step: 6100... Loss: 0.110148... Val Loss: 1.010333\n",
      "Epoch: 10/10... Step: 6200... Loss: 0.002546... Val Loss: 0.869962\n"
     ]
    }
   ],
   "source": [
    "LR = 0.001 #Definicao do fator de aprendizado\n",
    "PRINT_EVERY = 100 \n",
    "CLIP = 5 # Define a norma máxima dos gradientes\n",
    "\n",
    "# Define o criterio de cálculo de loss - BCE - Binary Cross Entropy, usado para classificacao de 2 classes\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Utiliza o otimizador Adam\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "# Quantidade de épocas\n",
    "epochs = 10\n",
    "counter = 0\n",
    "\n",
    "model.train()\n",
    "\n",
    "# itera as epocas\n",
    "for e in range(epochs):\n",
    "    print('epoch: {0}'.format(e))\n",
    "    \n",
    "    h = model.init_hidden(BATCH_SIZE)\n",
    "\n",
    "    # itera o loader de treinamento\n",
    "    for inputs, labels in train_loader:\n",
    "        counter += 1\n",
    "\n",
    "        h = tuple([each.data for each in h])\n",
    "        model.zero_grad()\n",
    "\n",
    "        inputs = inputs.type(torch.LongTensor)\n",
    "        output, h = model(inputs, h)\n",
    "\n",
    "        loss = criterion(output.squeeze(), labels.float())\n",
    "        loss.backward()\n",
    "\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), CLIP)\n",
    "        optimizer.step()\n",
    "\n",
    "        # Verifica se é para efetuar o processo de validacao (por padrao, a cada 100 iteracoes de treinamento, 1 faz a validacao)\n",
    "        if counter % PRINT_EVERY == 0:\n",
    "            val_h = model.init_hidden(BATCH_SIZE)\n",
    "            val_losses = []\n",
    "\n",
    "            model.eval()\n",
    "\n",
    "            # Itera sobre o data loader de validacao\n",
    "            for inputs, labels in valid_loader:\n",
    "                # Obtem a entrada, faz a predicao do modelo e computa a loss\n",
    "                val_h = tuple([each.data for each in val_h])\n",
    "                inputs = inputs.type(torch.LongTensor)\n",
    "                output, val_h = model(inputs, val_h)\n",
    "                val_loss = criterion(output.squeeze(), labels.float())\n",
    "                val_losses.append(val_loss.item())\n",
    "            \n",
    "            # Retorna para treinamento\n",
    "            model.train()\n",
    "\n",
    "            # Exibe o estado\n",
    "            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                  \"Step: {}...\".format(counter),\n",
    "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
    "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apos o modelo treinado, executa na base de testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.062\n",
      "Test accuracy: 0.783\n"
     ]
    }
   ],
   "source": [
    "test_losses = []\n",
    "num_correct = 0\n",
    "\n",
    "h = model.init_hidden(BATCH_SIZE)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Itera a base de testes\n",
    "for inputs, labels in test_loader:\n",
    "    # Obtem um valor e executa a inferencia no modelo\n",
    "    h = tuple([each.data for each in h])\n",
    "    \n",
    "    inputs = inputs.type(torch.LongTensor)\n",
    "    output, h = model(inputs, h)\n",
    "    \n",
    "    test_loss = criterion(output.squeeze(), labels.float())\n",
    "    test_losses.append(test_loss.item())\n",
    "    \n",
    "    # Converte para a classe de resultado - 0 ou 1\n",
    "    pred = torch.round(output.squeeze())\n",
    "    \n",
    "    # Checa com o valor original se esta correto e atualiza as contagens\n",
    "    correct_tensor = pred.eq(labels.float().view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.numpy())\n",
    "    num_correct += np.sum(correct)\n",
    "\n",
    "# Exibe as estatísticas de loss e acurácia\n",
    "print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n",
    "\n",
    "# Exibe a acuracia do modelo\n",
    "test_acc = num_correct/len(test_loader.dataset)\n",
    "print(\"Test accuracy: {:.3f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salva o melhor modelo no disco\n",
    "\n",
    "**Importante**: Foi definido, como boa prática, salvar o modelo completo e não apenas os seus pesos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './models/lstm_sentiment_analysis_1.h5'\n",
    "\n",
    "torch.save(model, PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, efetua a criacao do metodo de predicao, que recebe uma string, com base no modelo salvo.\n",
    "\n",
    "É possível observar que é feito o método `tokenize_review` que faz o mesmo pré-processamento realizado na etapa de treinamento, validação e testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This movie had the best acting and the dialogue was so good. I loved it.\n",
      "Predicted value: 0.997554\n",
      "Positive Review\n",
      "This movie was so terrible.\n",
      "Predicted value: 0.003912\n",
      "Negative Review\n"
     ]
    }
   ],
   "source": [
    "def tokenize_review(review):\n",
    "    review = review.lower()\n",
    "    txt = ''.join([c for c in review if c not in punctuation])\n",
    "    words = txt.split()\n",
    "    \n",
    "    \n",
    "    ints = []\n",
    "    \n",
    "    # Neste passo, filtra todas as palavras contidas no vocabulario\n",
    "    # Caso nao seja incluida, o valor fica como 0\n",
    "    ints.append([vocab_to_int[word] if vocab_to_int[word] != None else 0 for word in words])\n",
    "\n",
    "    return ints\n",
    "\n",
    "\n",
    "def predict(model, input_str, seq_length=280):\n",
    "    # Recebe o modelo e uma entrada de string\n",
    "    # O parametro seq_length deve ser o mesmo atribuido no treino e teste - \n",
    "    # corresponde ao tamanho maximo do texto\n",
    "    \n",
    "    print(input_str)\n",
    "    model_loaded.eval()\n",
    "    \n",
    "    # faz o pre processamento\n",
    "    ints = tokenize_review(input_str)\n",
    "    \n",
    "    # Extrai as features\n",
    "    features = pad_features(ints, seq_length)\n",
    "    \n",
    "    # Converte para tensor\n",
    "    feature_tensor = torch.from_numpy(features)\n",
    "    \n",
    "    # Inicia a predicao do modelo\n",
    "    batch_size = feature_tensor.size(0)\n",
    "    \n",
    "    h = model.init_hidden(batch_size)\n",
    "    \n",
    "    output, h = model(feature_tensor, h)\n",
    "    \n",
    "    # Arrendonda o valor predito - por ser sigmoid, vira entre 0 e 1, entao arredendo para ficar mais proximo do resultado\n",
    "    pred = torch.round(output.squeeze())\n",
    "    \n",
    "    print('Predicted value: {:.6f}'.format(output.item()))\n",
    "    \n",
    "    # faz a verificacao do que foi predito e exibe o resultado\n",
    "    if (pred.item() > 0):\n",
    "        print('Positive Review')\n",
    "    else:\n",
    "        print('Negative Review')\n",
    "\n",
    "model_loaded = torch.load(PATH)\n",
    "predict(model_loaded, 'This movie had the best acting and the dialogue was so good. I loved it.')\n",
    "predict(model_loaded, 'This movie was so terrible.')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "94b5bfc3a0f2df147d53edc1846b6310f977e163087d94f8db5227455afe7a72"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('.venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}